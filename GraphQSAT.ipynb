{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "GraphQSAT.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "md4JZ9dNr-cj"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "md4JZ9dNr-cj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSSjiEf1sjTf"
      },
      "source": [
        "%cd gdrive/My Drive"
      ],
      "id": "PSSjiEf1sjTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQDmH68WssAm"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('neuroSAT'):\n",
        "  !git clone --recurse-submodules https://github.com/dmeoli/neuroSAT\n",
        "  %cd neuroSAT\n",
        "else:\n",
        "  %cd neuroSAT\n",
        "  !git pull"
      ],
      "id": "wQDmH68WssAm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDLLNcrEt_il"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "id": "FDLLNcrEt_il",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMMK1om7bzWs"
      },
      "source": [
        "datasets = {'uniform-random-3-sat': {'train': ['uf50-218', 'uuf50-218',\n",
        "                                               'uf100-430', 'uuf100-430'],\n",
        "                                     'val': ['uf50-218', 'uuf50-218',\n",
        "                                             'uf100-430', 'uuf100-430'],\n",
        "                                     'inner_test': ['uf50-218', 'uuf50-218',\n",
        "                                                    'uf100-430', 'uuf100-430'],\n",
        "                                     'test': ['uf250-1065', 'uuf250-1065'],\n",
        "                                     'kt_test': ['flat30-60',\n",
        "                                                 'flat50-115',\n",
        "                                                 'flat75-180',\n",
        "                                                 'flat100-239',\n",
        "                                                 'flat125-301',\n",
        "                                                 'flat150-360',\n",
        "                                                 'flat175-417',\n",
        "                                                 'flat200-479']},\n",
        "            'graph-coloring': {'train': ['flat50-115'],\n",
        "                               'val': ['flat50-115'],\n",
        "                               'inner_test': ['flat50-115'],\n",
        "                               'test': ['flat30-60',\n",
        "                                        'flat75-180',\n",
        "                                        'flat100-239',\n",
        "                                        'flat125-301',\n",
        "                                        'flat150-360',\n",
        "                                        'flat175-417',\n",
        "                                        'flat200-479']}}"
      ],
      "id": "HMMK1om7bzWs",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "russian-ending"
      },
      "source": [
        "# GraphQSAT"
      ],
      "id": "russian-ending"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypffdwwc60GL"
      },
      "source": [
        "%cd GraphQSAT"
      ],
      "id": "Ypffdwwc60GL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hMESDiv-pWG"
      },
      "source": [
        "### Build C++"
      ],
      "id": "9hMESDiv-pWG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZF8lgna7tGm"
      },
      "source": [
        "%cd minisat\n",
        "!sudo ln -s --force /usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy /usr/include/numpy  # https://stackoverflow.com/a/44935933/5555994\n",
        "!make distclean && CXXFLAGS=-w make && make python-wrap PYTHON=python3.7\n",
        "!apt install swig\n",
        "!swig -fastdispatch -c++ -python minisat/gym/GymSolver.i\n",
        "%cd .."
      ],
      "id": "nZF8lgna7tGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH78QOrwiSVt"
      },
      "source": [
        "## Uniform Random 3-SAT\n",
        "\n",
        "We split *(u)uf50-218* and *(u)uf100-430* into three subsets: 800 training problems, 100 validation, and 100 test problems.\n",
        "\n",
        "For generalization experiments, we use 100 problems from all the other benchmarks.\n",
        "\n",
        "To evaluate the knowledge transfer properties of the trained models across different task families, we use 100 problems from all the *graph coloring* benchmarks."
      ],
      "id": "rH78QOrwiSVt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGI9Dj-FRXN4"
      },
      "source": [
        "PROBLEM_TYPE='uniform-random-3-sat'"
      ],
      "id": "HGI9Dj-FRXN4",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WecpwjxDQGm"
      },
      "source": [
        "!bash train_val_test_split.sh \"$PROBLEM_TYPE\""
      ],
      "id": "7WecpwjxDQGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqMVfDNR-_AV"
      },
      "source": [
        "### Add metadata for evaluation (train and validation set)"
      ],
      "id": "nqMVfDNR-_AV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bored-emphasis"
      },
      "source": [
        "for TRAIN_PROBLEM_NAME, VAL_PROBLEM_NAME in zip(datasets[PROBLEM_TYPE]['train'],\n",
        "                                                datasets[PROBLEM_TYPE]['val']):\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/train/\"$TRAIN_PROBLEM_NAME\"\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/val/\"$VAL_PROBLEM_NAME\""
      ],
      "id": "bored-emphasis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTTzlCOm_W4d"
      },
      "source": [
        "### Train"
      ],
      "id": "MTTzlCOm_W4d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rising-death"
      },
      "source": [
        "for TRAIN_PROBLEM_NAME, VAL_PROBLEM_NAME in zip(datasets[PROBLEM_TYPE]['train'],\n",
        "                                                datasets[PROBLEM_TYPE]['val']):\n",
        "  !python dqn.py \\\n",
        "    --logdir log \\\n",
        "    --env-name sat-v0 \\\n",
        "    --train-problems-paths ../data/\"$PROBLEM_TYPE\"/train/\"$TRAIN_PROBLEM_NAME\" \\\n",
        "    --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/val/\"$VAL_PROBLEM_NAME\" \\\n",
        "    --lr 0.00002 \\\n",
        "    --bsize 64 \\\n",
        "    --buffer-size 20000 \\\n",
        "    --eps-init 1.0 \\\n",
        "    --eps-final 0.01 \\\n",
        "    --gamma 0.99 \\\n",
        "    --eps-decay-steps 30000 \\\n",
        "    --batch-updates 50000 \\\n",
        "    --history-len 1 \\\n",
        "    --init-exploration-steps 5000 \\\n",
        "    --step-freq 4 \\\n",
        "    --target-update-freq 10 \\\n",
        "    --loss mse \\\n",
        "    --opt adam \\\n",
        "    --save-freq 500 \\\n",
        "    --grad_clip 1 \\\n",
        "    --grad_clip_norm_type 2 \\\n",
        "    --eval-freq 1000 \\\n",
        "    --eval-time-limit 3600 \\\n",
        "    --core-steps 4 \\\n",
        "    --expert-exploration-prob 0.0 \\\n",
        "    --priority_alpha 0.5 \\\n",
        "    --priority_beta 0.5 \\\n",
        "    --e2v-aggregator sum \\\n",
        "    --n_hidden 1 \\\n",
        "    --hidden_size 64 \\\n",
        "    --decoder_v_out_size 32 \\\n",
        "    --decoder_e_out_size 1 \\\n",
        "    --decoder_g_out_size 1 \\\n",
        "    --encoder_v_out_size 32 \\\n",
        "    --encoder_e_out_size 32 \\\n",
        "    --encoder_g_out_size 32 \\\n",
        "    --core_v_out_size 64 \\\n",
        "    --core_e_out_size 64 \\\n",
        "    --core_g_out_size 32 \\\n",
        "    --activation relu \\\n",
        "    --penalty_size 0.1 \\\n",
        "    --train_time_max_decisions_allowed 500 \\\n",
        "    --test_time_max_decisions_allowed 500 \\\n",
        "    --no_max_cap_fill_buffer \\\n",
        "    --lr_scheduler_gamma 1 \\\n",
        "    --lr_scheduler_frequency 3000 \\\n",
        "    --independent_block_layers 0"
      ],
      "id": "rising-death",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIFGn6JJRgdO"
      },
      "source": [
        "### Add metadata for evaluation (test set)"
      ],
      "id": "UIFGn6JJRgdO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmGaDnimPYun"
      },
      "source": [
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['inner_test']:\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/test/\"$PROBLEM_NAME\"\n",
        "\n",
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['test'] + datasets[PROBLEM_TYPE]['kt_test']:\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/\"$PROBLEM_NAME\""
      ],
      "id": "BmGaDnimPYun",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H_5kfS8X3wm"
      },
      "source": [
        "### Evaluate"
      ],
      "id": "2H_5kfS8X3wm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptB7-ZibX3yE"
      },
      "source": [
        "models = {'uf50-218': ('Aug04_16-28-54_98b46997a24d', \n",
        "                       'model_50001'),\n",
        "          'uuf50-218': ('Sep12_10-11-09_4730bf8f8ad0', \n",
        "                        'model_50006'),\n",
        "          'uf100-430': ('Aug04_21-40-43_98b46997a24d', \n",
        "                        'model_50061'),\n",
        "          'uuf100-430': ('Sep12_16-06-06_4730bf8f8ad0', \n",
        "                         'model_45085')}"
      ],
      "id": "ptB7-ZibX3yE",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZ1CBXbtzK8"
      },
      "source": [
        "We test these trained models on the inner test sets."
      ],
      "id": "djZ1CBXbtzK8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFxGGZdPX62D"
      },
      "source": [
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['inner_test']:\n",
        "  for MODEL_DECISION in [10, 50, 100, 300, 500, 1000]:\n",
        "    MODEL_DIR = models[PROBLEM_NAME][0]\n",
        "    CHECKPOINT = models[PROBLEM_NAME][1]\n",
        "    !python evaluate.py \\\n",
        "      --logdir log \\\n",
        "      --env-name sat-v0 \\\n",
        "      --core-steps -1 \\\n",
        "      --eps-final 0.0 \\\n",
        "      --eval-time-limit 100000000000000 \\\n",
        "      --no_restarts \\\n",
        "      --test_time_max_decisions_allowed \"$MODEL_DECISION\" \\\n",
        "      --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/test/\"$PROBLEM_NAME\" \\\n",
        "      --model-dir runs/\"$MODEL_DIR\" \\\n",
        "      --model-checkpoint \"$CHECKPOINT\".chkp \\\n",
        "      >> runs/\"$MODEL_DIR\"/\"$PROBLEM_NAME\"-graphqsat-max\"$MODEL_DECISION\".tsv"
      ],
      "id": "oFxGGZdPX62D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Ux737RuaoN"
      },
      "source": [
        "We test the trained models on the outer test sets."
      ],
      "id": "C1Ux737RuaoN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huspm-fG4ruP"
      },
      "source": [
        "for SAT_MODEL in models.keys():\n",
        "  for PROBLEM_NAME in datasets[PROBLEM_TYPE]['test']:\n",
        "    for MODEL_DECISION in [10, 50, 100, 300, 500, 1000]:\n",
        "      MODEL_DIR = models[SAT_MODEL][0]\n",
        "      CHECKPOINT = models[SAT_MODEL][1]\n",
        "      !python evaluate.py \\\n",
        "        --logdir log \\\n",
        "        --env-name sat-v0 \\\n",
        "        --core-steps -1 \\\n",
        "        --eps-final 0.0 \\\n",
        "        --eval-time-limit 100000000000000 \\\n",
        "        --no_restarts \\\n",
        "        --test_time_max_decisions_allowed \"$MODEL_DECISION\" \\\n",
        "        --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/\"$PROBLEM_NAME\" \\\n",
        "        --model-dir runs/\"$MODEL_DIR\" \\\n",
        "        --model-checkpoint \"$CHECKPOINT\".chkp \\\n",
        "        >> runs/\"$MODEL_DIR\"/\"$PROBLEM_NAME\"-graphqsat-max\"$MODEL_DECISION\".tsv"
      ],
      "id": "huspm-fG4ruP",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H7bHgHblOit"
      },
      "source": [
        "We test the trained models on the *graph coloring* test sets."
      ],
      "id": "-H7bHgHblOit"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfjCQpJzlNOS"
      },
      "source": [
        "for SAT_MODEL in models.keys():\n",
        "  for PROBLEM_NAME in datasets[PROBLEM_TYPE]['kt_test']:\n",
        "    for MODEL_DECISION in [10, 50, 100, 300, 500, 1000]:\n",
        "      MODEL_DIR = models[SAT_MODEL][0]\n",
        "      CHECKPOINT = models[SAT_MODEL][1]\n",
        "      !python evaluate.py \\\n",
        "        --logdir log \\\n",
        "        --env-name sat-v0 \\\n",
        "        --core-steps -1 \\\n",
        "        --eps-final 0.0 \\\n",
        "        --eval-time-limit 100000000000000 \\\n",
        "        --no_restarts \\\n",
        "        --test_time_max_decisions_allowed \"$MODEL_DECISION\" \\\n",
        "        --eval-problems-paths ../data/graph-coloring/\"$PROBLEM_NAME\" \\\n",
        "        --model-dir runs/\"$MODEL_DIR\" \\\n",
        "        --model-checkpoint \"$CHECKPOINT\".chkp \\\n",
        "        >> runs/\"$MODEL_DIR\"/\"$PROBLEM_NAME\"-graphqsat-max\"$MODEL_DECISION\".tsv"
      ],
      "id": "xfjCQpJzlNOS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw-KPx8glT7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e1b502-870f-4e14-c357-196272356aac"
      },
      "source": [
        "%cd .."
      ],
      "id": "Gw-KPx8glT7s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/neuro-sat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYw40NNfjCDL"
      },
      "source": [
        "## Graph Coloring\n",
        "\n",
        "Graph coloring benchmarks have only 100 problems each, except for *flat50-115* which contains 1000, so we split it into three subsets: 800 training problems, 100 validation, and 100 test problems.\n",
        "\n",
        "For generalization experiments, we use 100 problems from all the other benchmarks."
      ],
      "id": "VYw40NNfjCDL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ods6xm8nRs1x"
      },
      "source": [
        "PROBLEM_TYPE='graph-coloring'"
      ],
      "id": "Ods6xm8nRs1x",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG9OBAFGSCU8"
      },
      "source": [
        "!bash train_val_test_split.sh \"$PROBLEM_TYPE\""
      ],
      "id": "QG9OBAFGSCU8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-HPh7AVjCDM"
      },
      "source": [
        "### Add metadata for evaluation (train and validation set)"
      ],
      "id": "_-HPh7AVjCDM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n624I80gjCDM"
      },
      "source": [
        "for TRAIN_PROBLEM_NAME, VAL_PROBLEM_NAME in zip(datasets[PROBLEM_TYPE]['train'],\n",
        "                                                datasets[PROBLEM_TYPE]['val']):\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/train/\"$TRAIN_PROBLEM_NAME\"\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/val/\"$VAL_PROBLEM_NAME\""
      ],
      "id": "n624I80gjCDM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sloVrX1zjCDN"
      },
      "source": [
        "### Train"
      ],
      "id": "sloVrX1zjCDN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMwwOBfcjCDN"
      },
      "source": [
        "for TRAIN_PROBLEM_NAME, VAL_PROBLEM_NAME in zip(datasets[PROBLEM_TYPE]['train'],\n",
        "                                                datasets[PROBLEM_TYPE]['val']):\n",
        "  !python dqn.py \\\n",
        "    --logdir log \\\n",
        "    --env-name sat-v0 \\\n",
        "    --train-problems-paths ../data/\"$PROBLEM_TYPE\"/train/\"$TRAIN_PROBLEM_NAME\" \\\n",
        "    --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/val/\"$VAL_PROBLEM_NAME\" \\\n",
        "    --lr 0.00002 \\\n",
        "    --bsize 64 \\\n",
        "    --buffer-size 20000 \\\n",
        "    --eps-init 1.0 \\\n",
        "    --eps-final 0.01 \\\n",
        "    --gamma 0.99 \\\n",
        "    --eps-decay-steps 30000 \\\n",
        "    --batch-updates 50000 \\\n",
        "    --history-len 1 \\\n",
        "    --init-exploration-steps 5000 \\\n",
        "    --step-freq 4 \\\n",
        "    --target-update-freq 10 \\\n",
        "    --loss mse \\\n",
        "    --opt adam \\\n",
        "    --save-freq 500 \\\n",
        "    --grad_clip 0.1 \\\n",
        "    --grad_clip_norm_type 2 \\\n",
        "    --eval-freq 1000 \\\n",
        "    --eval-time-limit 3600 \\\n",
        "    --core-steps 4 \\\n",
        "    --expert-exploration-prob 0.0 \\\n",
        "    --priority_alpha 0.5 \\\n",
        "    --priority_beta 0.5 \\\n",
        "    --e2v-aggregator sum \\\n",
        "    --n_hidden 1 \\\n",
        "    --hidden_size 64 \\\n",
        "    --decoder_v_out_size 32 \\\n",
        "    --decoder_e_out_size 1 \\\n",
        "    --decoder_g_out_size 1 \\\n",
        "    --encoder_v_out_size 32 \\\n",
        "    --encoder_e_out_size 32 \\\n",
        "    --encoder_g_out_size 32 \\\n",
        "    --core_v_out_size 64 \\\n",
        "    --core_e_out_size 64 \\\n",
        "    --core_g_out_size 32 \\\n",
        "    --activation relu \\\n",
        "    --penalty_size 0.1 \\\n",
        "    --train_time_max_decisions_allowed 500 \\\n",
        "    --test_time_max_decisions_allowed 500 \\\n",
        "    --no_max_cap_fill_buffer \\\n",
        "    --lr_scheduler_gamma 1 \\\n",
        "    --lr_scheduler_frequency 3000 \\\n",
        "    --independent_block_layers 0"
      ],
      "id": "fMwwOBfcjCDN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MD6DHwwjCDN"
      },
      "source": [
        "### Add metadata for evaluation (test set)"
      ],
      "id": "1MD6DHwwjCDN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imKKT3snjCDO"
      },
      "source": [
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['inner_test']:\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/test/\"$PROBLEM_NAME\"\n",
        "\n",
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['test']:\n",
        "  !python add_metadata.py --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/\"$PROBLEM_NAME\""
      ],
      "id": "imKKT3snjCDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am0iALxRjCDO"
      },
      "source": [
        "### Evaluate"
      ],
      "id": "am0iALxRjCDO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1GmjNk3jCDO"
      },
      "source": [
        "MODEL_DIR='Sep10_12-34-08_19c1d7476815'\n",
        "CHECKPOINT='model_50003'"
      ],
      "id": "t1GmjNk3jCDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YQTwDwvjCDO"
      },
      "source": [
        "for PROBLEM_NAME in datasets[PROBLEM_TYPE]['test']:\n",
        "  for MODEL_DECISION in [10, 50, 100, 300, 500, 1000]:\n",
        "    !python evaluate.py \\\n",
        "      --logdir log \\\n",
        "      --env-name sat-v0 \\\n",
        "      --core-steps -1 \\\n",
        "      --eps-final 0.0 \\\n",
        "      --eval-time-limit 100000000000000 \\\n",
        "      --no_restarts \\\n",
        "      --test_time_max_decisions_allowed \"$MODEL_DECISION\" \\\n",
        "      --eval-problems-paths ../data/\"$PROBLEM_TYPE\"/\"$PROBLEM_NAME\" \\\n",
        "      --model-dir runs/\"$MODEL_DIR\" \\\n",
        "      --model-checkpoint \"$CHECKPOINT\".chkp \\\n",
        "      >> runs/\"$MODEL_DIR\"/\"$PROBLEM_NAME\"-graphqsat-max\"$MODEL_DECISION\".tsv"
      ],
      "id": "7YQTwDwvjCDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqnV3yURjCDO",
        "outputId": "89e1b502-870f-4e14-c357-196272356aac"
      },
      "source": [
        "%cd .."
      ],
      "id": "hqnV3yURjCDO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/neuro-sat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}